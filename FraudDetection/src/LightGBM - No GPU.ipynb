{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc, time\n",
    "#os.chdir('C:/Users/Paperspace/Desktop/Kaggle-Competitions/FraudDetection')\n",
    "os.chdir('C:\\Users/dhruv/Desktop/Kaggle/TalkingData/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'ip'            : 'uint32',\n",
    "    'app'           : 'uint16',\n",
    "    'device'        : 'uint16',\n",
    "    'os'            : 'uint16',\n",
    "    'channel'       : 'uint16',\n",
    "    'is_attributed' : 'uint8',\n",
    "    'click_id'      : 'uint32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handleClicktime(df):\n",
    "    df['click_hour']= (pd.to_datetime(df['click_time']).dt.round('H')).dt.hour\n",
    "    df['click_hour'] = df['click_hour'].astype('uint16')\n",
    "    df = df.drop(['click_time'], axis=1)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load train [115.85464644432068] sec\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "train = pd.read_csv('train.csv', dtype=dtypes, skiprows=range(1,133333333), nrows=33333333)\n",
    "print ('Time to load train [{}] sec'.format(time.time()-st_time))\n",
    "\n",
    "train_record_index = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load test [18.50202703475952] sec\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "test = pd.read_csv('test.csv')\n",
    "print ('Time to load test [{}] sec'.format(time.time()-st_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to handle click time [29.993566751480103] sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle click time\n",
    "st_time = time.time()\n",
    "train = handleClicktime(train)\n",
    "test = handleClicktime(test)\n",
    "print ('Time to handle click time [{}] sec'.format(time.time()-st_time))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df for submit\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['click_id'] = test['click_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get y\n",
    "Learning_Y = train['is_attributed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop zone\n",
    "test = test.drop(['click_id'], axis=1)\n",
    "train = train.drop(['is_attributed', 'attributed_time'], axis=1)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.concat([train, test])\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load df_ip_count with [5.974506616592407] seconds\n"
     ]
    }
   ],
   "source": [
    "# Count ip for both train and test df \n",
    "start_time = time.time()\n",
    "df_ip_count = df_merge['ip'].value_counts().reset_index(name='ip_count')\n",
    "df_ip_count.columns = ['ip', 'ip_count']\n",
    "print('Load df_ip_count with [{}] seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge = df_merge.merge(df_ip_count, on='ip', how='left', sort=False)\n",
    "df_merge['ip_count'] = df_merge['ip_count'].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = df_merge.drop(['ip'], axis=1)\n",
    "del df_ip_count\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_merge[:train_record_index]\n",
    "test = df_merge[train_record_index:]\n",
    "\n",
    "del df_merge\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: is_attributed, dtype: uint8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Learning_Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import recall_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_lgb(preds, d_train):\n",
    "    labels = d_train.get_label()\n",
    "    preds = np.where((preds > 0.5), 1, 0)\n",
    "    recs = recall_score(preds, labels)\n",
    "    return 'recall', recs, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'boosting' : 'gbdt', 'learning_rate' : 0.02, 'application' : 'binary', 'max_depth' : 7, 'num_leaves' : 26, \n",
    "         'data_random_seed' : 42, 'bagging_fraction' : 0.4, 'nthread' : 8, 'metric' : 'auc', 'is_unbalanced' : True}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)\n",
    "#del X_train\n",
    "#del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.870957\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[2]\ttraining's auc: 0.870964\n",
      "[3]\ttraining's auc: 0.870964\n",
      "[4]\ttraining's auc: 0.870984\n",
      "[5]\ttraining's auc: 0.870988\n",
      "[6]\ttraining's auc: 0.870991\n",
      "[7]\ttraining's auc: 0.870991\n",
      "[8]\ttraining's auc: 0.870991\n",
      "[9]\ttraining's auc: 0.871002\n",
      "[10]\ttraining's auc: 0.871001\n",
      "[11]\ttraining's auc: 0.871002\n",
      "[12]\ttraining's auc: 0.871005\n",
      "[13]\ttraining's auc: 0.871005\n",
      "[14]\ttraining's auc: 0.871006\n",
      "[15]\ttraining's auc: 0.871011\n",
      "[16]\ttraining's auc: 0.871011\n",
      "[17]\ttraining's auc: 0.871018\n",
      "[18]\ttraining's auc: 0.903166\n",
      "[19]\ttraining's auc: 0.90316\n",
      "[20]\ttraining's auc: 0.903329\n",
      "[21]\ttraining's auc: 0.903439\n",
      "[22]\ttraining's auc: 0.903451\n",
      "[23]\ttraining's auc: 0.90345\n",
      "[24]\ttraining's auc: 0.903455\n",
      "[25]\ttraining's auc: 0.903454\n",
      "[26]\ttraining's auc: 0.903458\n",
      "[27]\ttraining's auc: 0.90346\n",
      "[28]\ttraining's auc: 0.903467\n",
      "[29]\ttraining's auc: 0.903468\n",
      "[30]\ttraining's auc: 0.903467\n",
      "[31]\ttraining's auc: 0.903475\n",
      "[32]\ttraining's auc: 0.90348\n",
      "[33]\ttraining's auc: 0.903486\n",
      "[34]\ttraining's auc: 0.903476\n",
      "[35]\ttraining's auc: 0.903484\n",
      "[36]\ttraining's auc: 0.903492\n",
      "[37]\ttraining's auc: 0.903485\n",
      "[38]\ttraining's auc: 0.903489\n",
      "[39]\ttraining's auc: 0.903491\n",
      "[40]\ttraining's auc: 0.903492\n",
      "[41]\ttraining's auc: 0.903493\n",
      "[42]\ttraining's auc: 0.903492\n",
      "[43]\ttraining's auc: 0.903493\n",
      "[44]\ttraining's auc: 0.903493\n",
      "[45]\ttraining's auc: 0.903497\n",
      "[46]\ttraining's auc: 0.9035\n",
      "[47]\ttraining's auc: 0.9035\n",
      "[48]\ttraining's auc: 0.9035\n",
      "[49]\ttraining's auc: 0.903515\n",
      "[50]\ttraining's auc: 0.903516\n",
      "[51]\ttraining's auc: 0.903515\n",
      "[52]\ttraining's auc: 0.903516\n",
      "[53]\ttraining's auc: 0.903517\n",
      "[54]\ttraining's auc: 0.903517\n",
      "[55]\ttraining's auc: 0.903518\n",
      "[56]\ttraining's auc: 0.90352\n",
      "[57]\ttraining's auc: 0.90352\n",
      "[58]\ttraining's auc: 0.903521\n",
      "[59]\ttraining's auc: 0.903522\n",
      "[60]\ttraining's auc: 0.903529\n",
      "[61]\ttraining's auc: 0.90353\n",
      "[62]\ttraining's auc: 0.903532\n",
      "[63]\ttraining's auc: 0.903524\n",
      "[64]\ttraining's auc: 0.903537\n",
      "[65]\ttraining's auc: 0.903555\n",
      "[66]\ttraining's auc: 0.903556\n",
      "[67]\ttraining's auc: 0.903562\n",
      "[68]\ttraining's auc: 0.903565\n",
      "[69]\ttraining's auc: 0.903582\n",
      "[70]\ttraining's auc: 0.903581\n",
      "[71]\ttraining's auc: 0.903582\n",
      "[72]\ttraining's auc: 0.90359\n",
      "[73]\ttraining's auc: 0.903596\n",
      "[74]\ttraining's auc: 0.903597\n",
      "[75]\ttraining's auc: 0.903605\n",
      "[76]\ttraining's auc: 0.903602\n",
      "[77]\ttraining's auc: 0.903606\n",
      "[78]\ttraining's auc: 0.903609\n",
      "[79]\ttraining's auc: 0.903613\n",
      "[80]\ttraining's auc: 0.903614\n",
      "[81]\ttraining's auc: 0.903617\n",
      "[82]\ttraining's auc: 0.903618\n",
      "[83]\ttraining's auc: 0.903618\n",
      "[84]\ttraining's auc: 0.903629\n",
      "[85]\ttraining's auc: 0.903631\n",
      "[86]\ttraining's auc: 0.906837\n",
      "[87]\ttraining's auc: 0.906866\n",
      "[88]\ttraining's auc: 0.90687\n",
      "[89]\ttraining's auc: 0.906872\n",
      "[90]\ttraining's auc: 0.906944\n",
      "[91]\ttraining's auc: 0.906952\n",
      "[92]\ttraining's auc: 0.906959\n",
      "[93]\ttraining's auc: 0.907012\n",
      "[94]\ttraining's auc: 0.90702\n",
      "[95]\ttraining's auc: 0.907047\n",
      "[96]\ttraining's auc: 0.907053\n",
      "[97]\ttraining's auc: 0.907111\n",
      "[98]\ttraining's auc: 0.90711\n",
      "[99]\ttraining's auc: 0.907121\n",
      "[100]\ttraining's auc: 0.907127\n",
      "[101]\ttraining's auc: 0.907127\n",
      "[102]\ttraining's auc: 0.907142\n",
      "[103]\ttraining's auc: 0.907142\n",
      "[104]\ttraining's auc: 0.907148\n",
      "[105]\ttraining's auc: 0.907148\n",
      "[106]\ttraining's auc: 0.907154\n",
      "[107]\ttraining's auc: 0.907155\n",
      "[108]\ttraining's auc: 0.907159\n",
      "[109]\ttraining's auc: 0.907161\n",
      "[110]\ttraining's auc: 0.907162\n",
      "[111]\ttraining's auc: 0.907171\n",
      "[112]\ttraining's auc: 0.907173\n",
      "[113]\ttraining's auc: 0.907173\n",
      "[114]\ttraining's auc: 0.907179\n",
      "[115]\ttraining's auc: 0.907185\n",
      "[116]\ttraining's auc: 0.90719\n",
      "[117]\ttraining's auc: 0.907195\n",
      "[118]\ttraining's auc: 0.907192\n",
      "[119]\ttraining's auc: 0.907199\n",
      "[120]\ttraining's auc: 0.9072\n",
      "[121]\ttraining's auc: 0.907202\n",
      "[122]\ttraining's auc: 0.907203\n",
      "[123]\ttraining's auc: 0.910712\n",
      "[124]\ttraining's auc: 0.910742\n",
      "[125]\ttraining's auc: 0.910794\n",
      "[126]\ttraining's auc: 0.910803\n",
      "[127]\ttraining's auc: 0.910805\n",
      "[128]\ttraining's auc: 0.910813\n",
      "[129]\ttraining's auc: 0.910831\n",
      "[130]\ttraining's auc: 0.910842\n",
      "[131]\ttraining's auc: 0.91085\n",
      "[132]\ttraining's auc: 0.910865\n",
      "[133]\ttraining's auc: 0.910868\n",
      "[134]\ttraining's auc: 0.910875\n",
      "[135]\ttraining's auc: 0.91088\n",
      "[136]\ttraining's auc: 0.91088\n",
      "[137]\ttraining's auc: 0.910892\n",
      "[138]\ttraining's auc: 0.910905\n",
      "[139]\ttraining's auc: 0.910907\n",
      "[140]\ttraining's auc: 0.910912\n",
      "[141]\ttraining's auc: 0.910913\n",
      "[142]\ttraining's auc: 0.910917\n",
      "[143]\ttraining's auc: 0.910939\n",
      "[144]\ttraining's auc: 0.910949\n",
      "[145]\ttraining's auc: 0.910948\n",
      "[146]\ttraining's auc: 0.910953\n",
      "[147]\ttraining's auc: 0.910953\n",
      "[148]\ttraining's auc: 0.910955\n",
      "[149]\ttraining's auc: 0.910958\n",
      "[150]\ttraining's auc: 0.910959\n",
      "[151]\ttraining's auc: 0.910959\n",
      "[152]\ttraining's auc: 0.91096\n",
      "[153]\ttraining's auc: 0.910962\n",
      "[154]\ttraining's auc: 0.914043\n",
      "[155]\ttraining's auc: 0.91408\n",
      "[156]\ttraining's auc: 0.914084\n",
      "[157]\ttraining's auc: 0.914139\n",
      "[158]\ttraining's auc: 0.91415\n",
      "[159]\ttraining's auc: 0.914153\n",
      "[160]\ttraining's auc: 0.914154\n",
      "[161]\ttraining's auc: 0.914155\n",
      "[162]\ttraining's auc: 0.914157\n",
      "[163]\ttraining's auc: 0.914163\n",
      "[164]\ttraining's auc: 0.914164\n",
      "[165]\ttraining's auc: 0.914166\n",
      "[166]\ttraining's auc: 0.914168\n",
      "[167]\ttraining's auc: 0.914171\n",
      "[168]\ttraining's auc: 0.914174\n",
      "[169]\ttraining's auc: 0.914177\n",
      "[170]\ttraining's auc: 0.914178\n",
      "[171]\ttraining's auc: 0.914181\n",
      "[172]\ttraining's auc: 0.914184\n",
      "[173]\ttraining's auc: 0.914193\n",
      "[174]\ttraining's auc: 0.914198\n",
      "[175]\ttraining's auc: 0.914196\n",
      "[176]\ttraining's auc: 0.914196\n",
      "[177]\ttraining's auc: 0.914198\n",
      "[178]\ttraining's auc: 0.9142\n",
      "[179]\ttraining's auc: 0.914202\n",
      "[180]\ttraining's auc: 0.914202\n",
      "[181]\ttraining's auc: 0.914202\n",
      "[182]\ttraining's auc: 0.914208\n",
      "[183]\ttraining's auc: 0.914216\n",
      "[184]\ttraining's auc: 0.914222\n",
      "[185]\ttraining's auc: 0.914227\n",
      "[186]\ttraining's auc: 0.914315\n",
      "[187]\ttraining's auc: 0.914321\n",
      "[188]\ttraining's auc: 0.91424\n",
      "[189]\ttraining's auc: 0.91425\n",
      "[190]\ttraining's auc: 0.914261\n",
      "[191]\ttraining's auc: 0.914279\n",
      "[192]\ttraining's auc: 0.914298\n",
      "[193]\ttraining's auc: 0.914306\n",
      "[194]\ttraining's auc: 0.914316\n",
      "[195]\ttraining's auc: 0.914322\n",
      "[196]\ttraining's auc: 0.914333\n",
      "[197]\ttraining's auc: 0.91434\n",
      "[198]\ttraining's auc: 0.914538\n",
      "[199]\ttraining's auc: 0.914557\n",
      "[200]\ttraining's auc: 0.914579\n",
      "[201]\ttraining's auc: 0.914584\n",
      "[202]\ttraining's auc: 0.91459\n",
      "[203]\ttraining's auc: 0.9146\n",
      "[204]\ttraining's auc: 0.914606\n",
      "[205]\ttraining's auc: 0.918699\n",
      "[206]\ttraining's auc: 0.918708\n",
      "[207]\ttraining's auc: 0.918711\n",
      "[208]\ttraining's auc: 0.949836\n",
      "[209]\ttraining's auc: 0.949839\n",
      "[210]\ttraining's auc: 0.951194\n",
      "[211]\ttraining's auc: 0.951197\n",
      "[212]\ttraining's auc: 0.951328\n",
      "[213]\ttraining's auc: 0.951332\n",
      "[214]\ttraining's auc: 0.951408\n",
      "[215]\ttraining's auc: 0.951472\n",
      "[216]\ttraining's auc: 0.95185\n",
      "[217]\ttraining's auc: 0.95187\n",
      "[218]\ttraining's auc: 0.951954\n",
      "[219]\ttraining's auc: 0.952052\n",
      "[220]\ttraining's auc: 0.952166\n",
      "[221]\ttraining's auc: 0.952189\n",
      "[222]\ttraining's auc: 0.95224\n",
      "[223]\ttraining's auc: 0.952282\n",
      "[224]\ttraining's auc: 0.9523\n",
      "[225]\ttraining's auc: 0.952301\n",
      "[226]\ttraining's auc: 0.952317\n",
      "[227]\ttraining's auc: 0.952328\n",
      "[228]\ttraining's auc: 0.952344\n",
      "[229]\ttraining's auc: 0.952432\n",
      "[230]\ttraining's auc: 0.952577\n",
      "[231]\ttraining's auc: 0.952873\n",
      "[232]\ttraining's auc: 0.952882\n",
      "[233]\ttraining's auc: 0.952925\n",
      "[234]\ttraining's auc: 0.952932\n",
      "[235]\ttraining's auc: 0.953753\n",
      "[236]\ttraining's auc: 0.953761\n",
      "[237]\ttraining's auc: 0.953773\n",
      "[238]\ttraining's auc: 0.9538\n",
      "[239]\ttraining's auc: 0.953808\n",
      "[240]\ttraining's auc: 0.953817\n",
      "[241]\ttraining's auc: 0.953813\n",
      "[242]\ttraining's auc: 0.953884\n",
      "[243]\ttraining's auc: 0.953891\n",
      "[244]\ttraining's auc: 0.953895\n",
      "[245]\ttraining's auc: 0.953902\n",
      "[246]\ttraining's auc: 0.95394\n",
      "[247]\ttraining's auc: 0.953939\n",
      "[248]\ttraining's auc: 0.953952\n",
      "[249]\ttraining's auc: 0.954033\n",
      "[250]\ttraining's auc: 0.954039\n",
      "[251]\ttraining's auc: 0.954513\n",
      "[252]\ttraining's auc: 0.954508\n",
      "[253]\ttraining's auc: 0.954503\n",
      "[254]\ttraining's auc: 0.954511\n",
      "[255]\ttraining's auc: 0.954548\n",
      "[256]\ttraining's auc: 0.954554\n",
      "[257]\ttraining's auc: 0.954559\n",
      "[258]\ttraining's auc: 0.955003\n",
      "[259]\ttraining's auc: 0.955004\n",
      "[260]\ttraining's auc: 0.955018\n",
      "[261]\ttraining's auc: 0.955079\n",
      "[262]\ttraining's auc: 0.955174\n",
      "[263]\ttraining's auc: 0.955237\n",
      "[264]\ttraining's auc: 0.955296\n",
      "[265]\ttraining's auc: 0.955311\n",
      "[266]\ttraining's auc: 0.955315\n",
      "[267]\ttraining's auc: 0.955407\n",
      "[268]\ttraining's auc: 0.95548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[269]\ttraining's auc: 0.9555\n",
      "[270]\ttraining's auc: 0.955512\n",
      "[271]\ttraining's auc: 0.955525\n",
      "[272]\ttraining's auc: 0.955586\n",
      "[273]\ttraining's auc: 0.955597\n",
      "[274]\ttraining's auc: 0.955746\n",
      "[275]\ttraining's auc: 0.955745\n",
      "[276]\ttraining's auc: 0.955767\n",
      "[277]\ttraining's auc: 0.955823\n",
      "[278]\ttraining's auc: 0.955844\n",
      "[279]\ttraining's auc: 0.955878\n",
      "[280]\ttraining's auc: 0.955886\n",
      "[281]\ttraining's auc: 0.955886\n",
      "[282]\ttraining's auc: 0.955888\n",
      "[283]\ttraining's auc: 0.955925\n",
      "[284]\ttraining's auc: 0.955932\n",
      "[285]\ttraining's auc: 0.955955\n",
      "[286]\ttraining's auc: 0.955958\n",
      "[287]\ttraining's auc: 0.955956\n",
      "[288]\ttraining's auc: 0.955972\n",
      "[289]\ttraining's auc: 0.956324\n",
      "[290]\ttraining's auc: 0.956317\n",
      "[291]\ttraining's auc: 0.95646\n",
      "[292]\ttraining's auc: 0.956479\n",
      "[293]\ttraining's auc: 0.956476\n",
      "[294]\ttraining's auc: 0.956498\n",
      "[295]\ttraining's auc: 0.956522\n",
      "[296]\ttraining's auc: 0.95656\n",
      "[297]\ttraining's auc: 0.956769\n",
      "[298]\ttraining's auc: 0.956807\n",
      "[299]\ttraining's auc: 0.956822\n",
      "[300]\ttraining's auc: 0.956835\n",
      "[301]\ttraining's auc: 0.956919\n",
      "[302]\ttraining's auc: 0.95695\n",
      "[303]\ttraining's auc: 0.956998\n",
      "[304]\ttraining's auc: 0.957012\n",
      "[305]\ttraining's auc: 0.95702\n",
      "[306]\ttraining's auc: 0.956998\n",
      "[307]\ttraining's auc: 0.957039\n",
      "[308]\ttraining's auc: 0.957123\n",
      "[309]\ttraining's auc: 0.957173\n",
      "[310]\ttraining's auc: 0.957179\n",
      "[311]\ttraining's auc: 0.957199\n",
      "[312]\ttraining's auc: 0.957263\n",
      "[313]\ttraining's auc: 0.957307\n",
      "[314]\ttraining's auc: 0.957643\n",
      "[315]\ttraining's auc: 0.957649\n",
      "[316]\ttraining's auc: 0.957666\n",
      "[317]\ttraining's auc: 0.957683\n",
      "[318]\ttraining's auc: 0.957693\n",
      "[319]\ttraining's auc: 0.957708\n",
      "[320]\ttraining's auc: 0.957727\n",
      "[321]\ttraining's auc: 0.957747\n",
      "[322]\ttraining's auc: 0.957739\n",
      "[323]\ttraining's auc: 0.957759\n",
      "[324]\ttraining's auc: 0.95777\n",
      "[325]\ttraining's auc: 0.957759\n",
      "[326]\ttraining's auc: 0.957785\n",
      "[327]\ttraining's auc: 0.957786\n",
      "[328]\ttraining's auc: 0.9578\n",
      "[329]\ttraining's auc: 0.957814\n",
      "[330]\ttraining's auc: 0.95783\n",
      "[331]\ttraining's auc: 0.958697\n",
      "[332]\ttraining's auc: 0.958734\n",
      "[333]\ttraining's auc: 0.958796\n",
      "[334]\ttraining's auc: 0.958898\n",
      "[335]\ttraining's auc: 0.958741\n",
      "[336]\ttraining's auc: 0.958749\n",
      "[337]\ttraining's auc: 0.958681\n",
      "[338]\ttraining's auc: 0.958722\n",
      "[339]\ttraining's auc: 0.958706\n",
      "[340]\ttraining's auc: 0.95897\n",
      "[341]\ttraining's auc: 0.959055\n",
      "[342]\ttraining's auc: 0.958896\n",
      "[343]\ttraining's auc: 0.959034\n",
      "[344]\ttraining's auc: 0.959241\n",
      "[345]\ttraining's auc: 0.959254\n",
      "[346]\ttraining's auc: 0.959217\n",
      "[347]\ttraining's auc: 0.95923\n",
      "[348]\ttraining's auc: 0.959221\n",
      "[349]\ttraining's auc: 0.959323\n",
      "[350]\ttraining's auc: 0.959333\n",
      "[351]\ttraining's auc: 0.959332\n",
      "[352]\ttraining's auc: 0.959339\n",
      "[353]\ttraining's auc: 0.959363\n",
      "[354]\ttraining's auc: 0.95937\n",
      "[355]\ttraining's auc: 0.959206\n",
      "[356]\ttraining's auc: 0.959216\n",
      "[357]\ttraining's auc: 0.959231\n",
      "[358]\ttraining's auc: 0.959353\n",
      "[359]\ttraining's auc: 0.959282\n",
      "[360]\ttraining's auc: 0.959428\n",
      "[361]\ttraining's auc: 0.959663\n",
      "[362]\ttraining's auc: 0.959695\n",
      "[363]\ttraining's auc: 0.959695\n",
      "[364]\ttraining's auc: 0.959706\n",
      "[365]\ttraining's auc: 0.959708\n",
      "[366]\ttraining's auc: 0.95972\n",
      "[367]\ttraining's auc: 0.959741\n",
      "[368]\ttraining's auc: 0.959772\n",
      "[369]\ttraining's auc: 0.959776\n",
      "[370]\ttraining's auc: 0.959987\n",
      "[371]\ttraining's auc: 0.960009\n",
      "[372]\ttraining's auc: 0.96003\n",
      "[373]\ttraining's auc: 0.960057\n",
      "[374]\ttraining's auc: 0.960069\n",
      "[375]\ttraining's auc: 0.960089\n",
      "[376]\ttraining's auc: 0.961004\n",
      "[377]\ttraining's auc: 0.961088\n",
      "[378]\ttraining's auc: 0.961179\n",
      "[379]\ttraining's auc: 0.961215\n",
      "[380]\ttraining's auc: 0.961219\n",
      "[381]\ttraining's auc: 0.961241\n",
      "[382]\ttraining's auc: 0.961263\n",
      "[383]\ttraining's auc: 0.961283\n",
      "[384]\ttraining's auc: 0.961301\n",
      "[385]\ttraining's auc: 0.961312\n",
      "[386]\ttraining's auc: 0.961341\n",
      "[387]\ttraining's auc: 0.961273\n",
      "[388]\ttraining's auc: 0.961267\n",
      "[389]\ttraining's auc: 0.9613\n",
      "[390]\ttraining's auc: 0.961312\n",
      "[391]\ttraining's auc: 0.961415\n",
      "[392]\ttraining's auc: 0.961437\n",
      "[393]\ttraining's auc: 0.961455\n",
      "[394]\ttraining's auc: 0.961428\n",
      "[395]\ttraining's auc: 0.961518\n",
      "[396]\ttraining's auc: 0.961536\n",
      "[397]\ttraining's auc: 0.961595\n",
      "[398]\ttraining's auc: 0.961647\n",
      "[399]\ttraining's auc: 0.961669\n",
      "[400]\ttraining's auc: 0.961681\n",
      "[401]\ttraining's auc: 0.961706\n",
      "[402]\ttraining's auc: 0.96173\n",
      "[403]\ttraining's auc: 0.961738\n",
      "[404]\ttraining's auc: 0.961743\n",
      "[405]\ttraining's auc: 0.96178\n",
      "[406]\ttraining's auc: 0.961797\n",
      "[407]\ttraining's auc: 0.961806\n",
      "[408]\ttraining's auc: 0.961819\n",
      "[409]\ttraining's auc: 0.961829\n",
      "[410]\ttraining's auc: 0.961814\n",
      "[411]\ttraining's auc: 0.96183\n",
      "[412]\ttraining's auc: 0.961849\n",
      "[413]\ttraining's auc: 0.961904\n",
      "[414]\ttraining's auc: 0.961913\n",
      "[415]\ttraining's auc: 0.961924\n",
      "[416]\ttraining's auc: 0.961931\n",
      "[417]\ttraining's auc: 0.962003\n",
      "[418]\ttraining's auc: 0.962016\n",
      "[419]\ttraining's auc: 0.962024\n",
      "[420]\ttraining's auc: 0.962146\n",
      "[421]\ttraining's auc: 0.962162\n",
      "[422]\ttraining's auc: 0.962191\n",
      "[423]\ttraining's auc: 0.9622\n",
      "[424]\ttraining's auc: 0.962182\n",
      "[425]\ttraining's auc: 0.962225\n",
      "[426]\ttraining's auc: 0.962238\n",
      "[427]\ttraining's auc: 0.962312\n",
      "[428]\ttraining's auc: 0.962325\n",
      "[429]\ttraining's auc: 0.962326\n",
      "[430]\ttraining's auc: 0.962334\n",
      "[431]\ttraining's auc: 0.962383\n",
      "[432]\ttraining's auc: 0.962395\n",
      "[433]\ttraining's auc: 0.962413\n",
      "[434]\ttraining's auc: 0.962433\n",
      "[435]\ttraining's auc: 0.962445\n",
      "[436]\ttraining's auc: 0.962459\n",
      "[437]\ttraining's auc: 0.962486\n",
      "[438]\ttraining's auc: 0.962476\n",
      "[439]\ttraining's auc: 0.96264\n",
      "[440]\ttraining's auc: 0.962677\n",
      "[441]\ttraining's auc: 0.962663\n",
      "[442]\ttraining's auc: 0.962695\n",
      "[443]\ttraining's auc: 0.962707\n",
      "[444]\ttraining's auc: 0.962721\n",
      "[445]\ttraining's auc: 0.962724\n",
      "[446]\ttraining's auc: 0.962756\n",
      "[447]\ttraining's auc: 0.962787\n",
      "[448]\ttraining's auc: 0.962807\n",
      "[449]\ttraining's auc: 0.962832\n",
      "[450]\ttraining's auc: 0.962907\n",
      "[451]\ttraining's auc: 0.962963\n",
      "[452]\ttraining's auc: 0.962955\n",
      "[453]\ttraining's auc: 0.962973\n",
      "[454]\ttraining's auc: 0.96302\n",
      "[455]\ttraining's auc: 0.96306\n",
      "[456]\ttraining's auc: 0.963052\n",
      "[457]\ttraining's auc: 0.963093\n",
      "[458]\ttraining's auc: 0.963092\n",
      "[459]\ttraining's auc: 0.963133\n",
      "[460]\ttraining's auc: 0.963168\n",
      "[461]\ttraining's auc: 0.963172\n",
      "[462]\ttraining's auc: 0.963173\n",
      "[463]\ttraining's auc: 0.963211\n",
      "[464]\ttraining's auc: 0.963235\n",
      "[465]\ttraining's auc: 0.963259\n",
      "[466]\ttraining's auc: 0.963259\n",
      "[467]\ttraining's auc: 0.963258\n",
      "[468]\ttraining's auc: 0.963285\n",
      "[469]\ttraining's auc: 0.963299\n",
      "[470]\ttraining's auc: 0.963312\n",
      "[471]\ttraining's auc: 0.963338\n",
      "[472]\ttraining's auc: 0.963341\n",
      "[473]\ttraining's auc: 0.963366\n",
      "[474]\ttraining's auc: 0.963389\n",
      "[475]\ttraining's auc: 0.963391\n",
      "[476]\ttraining's auc: 0.963407\n",
      "[477]\ttraining's auc: 0.96341\n",
      "[478]\ttraining's auc: 0.963457\n",
      "[479]\ttraining's auc: 0.963486\n",
      "[480]\ttraining's auc: 0.963505\n",
      "[481]\ttraining's auc: 0.963526\n",
      "[482]\ttraining's auc: 0.96353\n",
      "[483]\ttraining's auc: 0.963556\n",
      "[484]\ttraining's auc: 0.963562\n",
      "[485]\ttraining's auc: 0.963586\n",
      "[486]\ttraining's auc: 0.963611\n",
      "[487]\ttraining's auc: 0.963628\n",
      "[488]\ttraining's auc: 0.963632\n",
      "[489]\ttraining's auc: 0.963661\n",
      "[490]\ttraining's auc: 0.963674\n",
      "[491]\ttraining's auc: 0.963696\n",
      "[492]\ttraining's auc: 0.963696\n",
      "[493]\ttraining's auc: 0.96372\n",
      "[494]\ttraining's auc: 0.963732\n",
      "[495]\ttraining's auc: 0.963751\n",
      "[496]\ttraining's auc: 0.963779\n",
      "[497]\ttraining's auc: 0.963789\n",
      "[498]\ttraining's auc: 0.963805\n",
      "[499]\ttraining's auc: 0.963821\n",
      "[500]\ttraining's auc: 0.963821\n",
      "[501]\ttraining's auc: 0.963842\n",
      "[502]\ttraining's auc: 0.963863\n",
      "[503]\ttraining's auc: 0.963872\n",
      "[504]\ttraining's auc: 0.963886\n",
      "[505]\ttraining's auc: 0.96391\n",
      "[506]\ttraining's auc: 0.963923\n",
      "[507]\ttraining's auc: 0.963934\n",
      "[508]\ttraining's auc: 0.963953\n",
      "[509]\ttraining's auc: 0.964105\n",
      "[510]\ttraining's auc: 0.964119\n",
      "[511]\ttraining's auc: 0.964139\n",
      "[512]\ttraining's auc: 0.964157\n",
      "[513]\ttraining's auc: 0.964176\n",
      "[514]\ttraining's auc: 0.964179\n",
      "[515]\ttraining's auc: 0.964189\n",
      "[516]\ttraining's auc: 0.9642\n",
      "[517]\ttraining's auc: 0.964252\n",
      "[518]\ttraining's auc: 0.96427\n",
      "[519]\ttraining's auc: 0.964282\n",
      "[520]\ttraining's auc: 0.964311\n",
      "[521]\ttraining's auc: 0.964328\n",
      "[522]\ttraining's auc: 0.964344\n",
      "[523]\ttraining's auc: 0.964353\n",
      "[524]\ttraining's auc: 0.964378\n",
      "[525]\ttraining's auc: 0.964385\n",
      "[526]\ttraining's auc: 0.964408\n",
      "[527]\ttraining's auc: 0.964415\n",
      "[528]\ttraining's auc: 0.964445\n",
      "[529]\ttraining's auc: 0.964464\n",
      "[530]\ttraining's auc: 0.964474\n",
      "[531]\ttraining's auc: 0.964481\n",
      "[532]\ttraining's auc: 0.964488\n",
      "[533]\ttraining's auc: 0.964511\n",
      "[534]\ttraining's auc: 0.964526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[535]\ttraining's auc: 0.964533\n",
      "[536]\ttraining's auc: 0.964549\n",
      "[537]\ttraining's auc: 0.964557\n",
      "[538]\ttraining's auc: 0.964581\n",
      "[539]\ttraining's auc: 0.964601\n",
      "[540]\ttraining's auc: 0.964611\n",
      "[541]\ttraining's auc: 0.964627\n",
      "[542]\ttraining's auc: 0.964657\n",
      "[543]\ttraining's auc: 0.964671\n",
      "[544]\ttraining's auc: 0.964697\n",
      "[545]\ttraining's auc: 0.964699\n",
      "[546]\ttraining's auc: 0.964706\n",
      "[547]\ttraining's auc: 0.964725\n",
      "[548]\ttraining's auc: 0.964733\n",
      "[549]\ttraining's auc: 0.964757\n",
      "[550]\ttraining's auc: 0.964781\n",
      "[551]\ttraining's auc: 0.964784\n",
      "[552]\ttraining's auc: 0.964789\n",
      "[553]\ttraining's auc: 0.964801\n",
      "[554]\ttraining's auc: 0.96483\n",
      "[555]\ttraining's auc: 0.964841\n",
      "[556]\ttraining's auc: 0.964844\n",
      "[557]\ttraining's auc: 0.96485\n",
      "[558]\ttraining's auc: 0.964875\n",
      "[559]\ttraining's auc: 0.964878\n",
      "[560]\ttraining's auc: 0.964881\n",
      "[561]\ttraining's auc: 0.964887\n",
      "[562]\ttraining's auc: 0.964913\n",
      "[563]\ttraining's auc: 0.964927\n",
      "[564]\ttraining's auc: 0.964954\n",
      "[565]\ttraining's auc: 0.964956\n",
      "[566]\ttraining's auc: 0.964979\n",
      "[567]\ttraining's auc: 0.964983\n",
      "[568]\ttraining's auc: 0.964985\n",
      "[569]\ttraining's auc: 0.964999\n",
      "[570]\ttraining's auc: 0.965026\n",
      "[571]\ttraining's auc: 0.965033\n",
      "[572]\ttraining's auc: 0.965042\n",
      "[573]\ttraining's auc: 0.965046\n",
      "[574]\ttraining's auc: 0.965062\n",
      "[575]\ttraining's auc: 0.965077\n",
      "[576]\ttraining's auc: 0.965089\n",
      "[577]\ttraining's auc: 0.9651\n",
      "[578]\ttraining's auc: 0.965102\n",
      "[579]\ttraining's auc: 0.965105\n",
      "[580]\ttraining's auc: 0.965126\n",
      "[581]\ttraining's auc: 0.965129\n",
      "[582]\ttraining's auc: 0.96514\n",
      "[583]\ttraining's auc: 0.965143\n",
      "[584]\ttraining's auc: 0.965148\n",
      "[585]\ttraining's auc: 0.965154\n",
      "[586]\ttraining's auc: 0.965157\n",
      "[587]\ttraining's auc: 0.96518\n",
      "[588]\ttraining's auc: 0.965191\n",
      "[589]\ttraining's auc: 0.965193\n",
      "[590]\ttraining's auc: 0.965195\n",
      "[591]\ttraining's auc: 0.965209\n",
      "[592]\ttraining's auc: 0.965213\n",
      "[593]\ttraining's auc: 0.965215\n",
      "[594]\ttraining's auc: 0.965223\n",
      "[595]\ttraining's auc: 0.965242\n",
      "[596]\ttraining's auc: 0.965248\n",
      "[597]\ttraining's auc: 0.965265\n",
      "[598]\ttraining's auc: 0.965268\n",
      "[599]\ttraining's auc: 0.965292\n",
      "[600]\ttraining's auc: 0.965309\n",
      "[601]\ttraining's auc: 0.965314\n",
      "[602]\ttraining's auc: 0.96532\n",
      "[603]\ttraining's auc: 0.965325\n",
      "[604]\ttraining's auc: 0.965347\n",
      "[605]\ttraining's auc: 0.96535\n",
      "[606]\ttraining's auc: 0.965361\n",
      "[607]\ttraining's auc: 0.965363\n",
      "[608]\ttraining's auc: 0.965379\n",
      "[609]\ttraining's auc: 0.965385\n",
      "[610]\ttraining's auc: 0.96539\n",
      "[611]\ttraining's auc: 0.965413\n",
      "[612]\ttraining's auc: 0.965415\n",
      "[613]\ttraining's auc: 0.96543\n",
      "[614]\ttraining's auc: 0.965433\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-8775ecec98ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevals_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_train\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   1626\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m         \"\"\"\n\u001b[1;32m-> 1628\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__train_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   1896\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1898\u001b[1;33m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[0;32m   1899\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length of eval results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evals_results = {}\n",
    "d_train = lgb.Dataset(train, label = Learning_Y)\n",
    "\n",
    "watchlist = [d_train]\n",
    "\n",
    "model = lgb.train(params, d_train, valid_sets = watchlist, evals_result = evals_results, num_boost_round = 1000, early_stopping_rounds = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-a1be7f3c88e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lgbmmodel.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save_model('lgbmmodel.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = model.predict(test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete training files\n",
    "del d_train\n",
    "del d_valid\n",
    "del train_X\n",
    "del valid_X\n",
    "del train_y\n",
    "del valid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 13\n",
      "building tree 3 of 13\n",
      "building tree 4 of 13\n",
      "building tree 5 of 13\n",
      "building tree 6 of 13\n",
      "building tree 7 of 13\n",
      "building tree 8 of 13\n",
      "building tree 9 of 13\n",
      "building tree 10 of 13\n",
      "building tree 11 of 13\n",
      "building tree 12 of 13\n",
      "building tree 13 of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 50.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=13, n_jobs=1,\n",
       "            oob_score=False, random_state=44, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=13, max_depth=13, random_state=44,verbose=2)\n",
    "#clf.fit(train, Learning_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   34.7s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict_proba(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.879047e+07</td>\n",
       "      <td>1.879047e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.395234e+06</td>\n",
       "      <td>3.671852e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.424341e+06</td>\n",
       "      <td>3.458478e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.697617e+06</td>\n",
       "      <td>2.936116e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.395234e+06</td>\n",
       "      <td>4.071790e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.409285e+07</td>\n",
       "      <td>6.634249e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.879047e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           click_id  is_attributed\n",
       "count  1.879047e+07   1.879047e+07\n",
       "mean   9.395234e+06   3.671852e-03\n",
       "std    5.424341e+06   3.458478e-02\n",
       "min    0.000000e+00   0.000000e+00\n",
       "25%    4.697617e+06   2.936116e-04\n",
       "50%    9.395234e+06   4.071790e-04\n",
       "75%    1.409285e+07   6.634249e-04\n",
       "max    1.879047e+07   1.000000e+00"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit['is_attributed'] = predictions[:,1]\n",
    "df_submit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
